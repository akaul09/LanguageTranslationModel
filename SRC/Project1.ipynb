{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akaul09/LanguageTranslationModel/blob/main/Project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P-EWGUqp3qBF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.17.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.26.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/ahyushkaul/Library/Python/3.11/lib/python/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.0.1)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.8.0)\n",
            "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.0.1)\n",
            "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.15.2)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.8.0)\n",
            "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (1.26.0)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (10.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->torchvision) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ahyushkaul/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/ahyushkaul/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n",
        "%pip install torch\n",
        "%pip install torch torchvision\n",
        "%pip install pandas\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O61TLZsHPsH5",
        "outputId": "332f74dc-1f94-4a4a-fb4c-06635b5d6ca9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TRj2vUV8MMEz",
        "outputId": "a7a9783b-a0c1-426c-bdef-082cdfbb3f0e"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('eng_-french.csv')\n",
        "df = df[0:25000]\n",
        "english = df[\"English words/sentences\"]\n",
        "english = list(english)\n",
        "french = df[\"French words/sentences\"]\n",
        "french = list(french)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LMSlMXQmREy4"
      },
      "outputs": [],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for english_phrase, french_translation in zip(english, french):\n",
        "    encoded = tokenizer(english_phrase, french_translation, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids.append(encoded['input_ids'])\n",
        "    attention_masks.append(encoded['attention_mask'])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_length = max(len(seq[0]) for seq in input_ids)\n",
        "\n",
        "input_id_padded = []\n",
        "attention_masks_padded = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    pad_length = max_length - len(seq[0])\n",
        "    input_id_padded.append(torch.cat([seq[0], torch.tensor([tokenizer.pad_token_id] * pad_length)]))\n",
        "    \n",
        "for seq in attention_masks:\n",
        "    pad_length = max_length - len(seq[0])\n",
        "    attention_masks_padded.append(torch.cat([seq[0], torch.tensor([0] * pad_length)]))\n",
        "\n",
        "input_id_padded = torch.stack(input_id_padded, dim=0)\n",
        "attention_masks_padded = torch.stack(attention_masks_padded, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = torch.zeros(len(english))\n",
        "dataset = TensorDataset(input_id_padded, attention_masks_padded,labels)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/sq/vvldb71x5fxcjhtx6mtb7b040000gn/T/ipykernel_8443/331543109.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  output = model(torch.tensor(input_id).to(torch.int64), attention_mask=attention_mask_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Loss: 0.0000\n",
            "Epoch 2/2, Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "num_epoch = 2\n",
        "for epoch in range(num_epoch):\n",
        "    model.train()\n",
        "    total_training_loss = 0\n",
        "    for phrase in dataloader:\n",
        "        phrase = tuple(t.to('cpu') for t in phrase)\n",
        "        input_id, attention_mask_train, training_labels = phrase\n",
        "        output = model(torch.tensor(input_id).to(torch.int64), attention_mask=attention_mask_train)\n",
        "        loss = output.loss\n",
        "        if loss is not None:  \n",
        "            total_training_loss += loss.item()\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "        optimizer.zero_grad()\n",
        "        optimizer.step()\n",
        "    average_loss = total_training_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epoch}, Loss: {average_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('fine_tuned_translation_model/tokenizer_config.json',\n",
              " 'fine_tuned_translation_model/special_tokens_map.json',\n",
              " 'fine_tuned_translation_model/vocab.txt',\n",
              " 'fine_tuned_translation_model/added_tokens.json')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"fine_tuned_translation_model\")\n",
        "tokenizer.save_pretrained(\"fine_tuned_translation_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"fine_tuned_translation_model\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"fine_tuned_translation_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_english_sentences = [\"Hi.\", \"Translate this sentence.\", \"What's the weather like today?\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for english_sentence in test_english_sentences:\n",
        "    encoded = tokenizer(english_sentence, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids.append(encoded['input_ids'])\n",
        "    attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_length = max(len(seq[0]) for seq in input_ids)\n",
        "\n",
        "input_id_padded2 = []\n",
        "attention_masks_padded2 = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    pad_length = max_length - len(seq[0])\n",
        "    input_id_padded2.append(torch.cat([seq[0], torch.tensor([tokenizer.pad_token_id] * pad_length)]))\n",
        "    \n",
        "for seq in attention_masks:\n",
        "    pad_length = max_length - len(seq[0])\n",
        "    attention_masks_padded2.append(torch.cat([seq[0], torch.tensor([0] * pad_length)]))\n",
        "\n",
        "input_id_padded2 = torch.stack(input_id_padded2, dim=0)\n",
        "attention_masks_padded2 = torch.stack(attention_masks_padded2, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_masks_padded2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input English: Hi.\n",
            "Predicted French: [unused1]\n",
            "\n",
            "Input English: Translate this sentence.\n",
            "Predicted French: [unused1]\n",
            "\n",
            "Input English: What's the weather like today?\n",
            "Predicted French: [unused1]\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/sq/vvldb71x5fxcjhtx6mtb7b040000gn/T/ipykernel_8443/4115355536.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  outputs = model(torch.tensor(input_id_padded2).to(torch.int64), attention_mask=attention_masks_padded2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(torch.tensor(input_id_padded2).to(torch.int64), attention_mask=attention_masks_padded2)\n",
        "\n",
        "logits = outputs.logits\n",
        "\n",
        "predicted_labels = (logits > 0).int()\n",
        "predicted_french_sentences = [tokenizer.decode(ids, skip_special_tokens=True) for ids in predicted_labels]\n",
        "\n",
        "for i, (english_sentence, french_translation) in enumerate(zip(test_english_sentences, predicted_french_sentences)):\n",
        "    print(f\"Input English: {english_sentence}\")\n",
        "    print(f\"Predicted French: {french_translation}\")\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
